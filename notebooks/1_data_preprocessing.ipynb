{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb5267d6",
   "metadata": {},
   "source": [
    "# ðŸ§¼ Data Preprocessing for Financial Sentiment Analysis\n",
    "\n",
    "This notebook handles the **loading, cleaning, standardization, and splitting** of multiple financial sentiment datasets to create a unified dataset for benchmarking.\n",
    "\n",
    "We will:\n",
    "\n",
    "-   Load datasets from HuggingFace and local files\n",
    "-   Normalize labels and text columns\n",
    "-   Clean the text using a reusable cleaning function\n",
    "-   Split into training and validation sets\n",
    "-   Export for reuse in downstream notebooks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be04011f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from datasets import load_dataset\n",
    "from IPython.display import display, display_markdown\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b19dd98",
   "metadata": {},
   "source": [
    "### ðŸ“¥ Load Datasets\n",
    "\n",
    "We will work with four datasets:\n",
    "\n",
    "1. **Twitter Financial News** â€” Real-world Twitter sentiment around finance.\n",
    "2. **Financial PhraseBank (FPB)** â€” Annotated financial sentences.\n",
    "3. **FiQA 2018** â€” Sentence-level sentiment in financial Q&A and news. (961 rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e4a27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter Financial News\n",
    "twitter_train = pd.read_csv(\n",
    "    \"hf://datasets/zeroshot/twitter-financial-news-sentiment/sent_train.csv\"\n",
    ")\n",
    "twitter_val = pd.read_csv(\n",
    "    \"hf://datasets/zeroshot/twitter-financial-news-sentiment/sent_valid.csv\"\n",
    ")\n",
    "twitter = pd.concat([twitter_train, twitter_val], ignore_index=True)\n",
    "\n",
    "# Financial PhraseBank\n",
    "fpb = pd.DataFrame(\n",
    "    load_dataset(\"takala/financial_phrasebank\", \"sentences_50agree\")[\n",
    "        \"train\"\n",
    "    ]  # >=50% agreement on sentiment\n",
    ")\n",
    "\n",
    "# FiQA\n",
    "fiqa_ds = load_dataset(\"pauri32/fiqa-2018\")\n",
    "fiqa = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame(fiqa_ds[\"train\"]),\n",
    "        pd.DataFrame(fiqa_ds[\"validation\"]),\n",
    "        pd.DataFrame(fiqa_ds[\"test\"]),\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "# Store the raw datasets in CSV format\n",
    "twitter.to_csv(\"../data/raw/twitter_financial_news.csv\", index=False)\n",
    "fpb.to_csv(\"../data/raw/financial_phrasebank.csv\", index=False)\n",
    "fiqa.to_csv(\"../data/raw/fiqa_2018.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6702163f",
   "metadata": {},
   "source": [
    "### Visualizing the Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b36b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "##### Twitter Dataset"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$BYND - JPMorgan reels in expectations on Beyo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$CCL $RCL - Nomura points to bookings weakness...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$CX - Cemex cut at Credit Suisse, J.P. Morgan ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$ESS: BTIG Research cuts to Neutral https://t....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$FNKO - Funko slides after Piper Jaffray PT cu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  $BYND - JPMorgan reels in expectations on Beyo...      0\n",
       "1  $CCL $RCL - Nomura points to bookings weakness...      0\n",
       "2  $CX - Cemex cut at Credit Suisse, J.P. Morgan ...      0\n",
       "3  $ESS: BTIG Research cuts to Neutral https://t....      0\n",
       "4  $FNKO - Funko slides after Piper Jaffray PT cu...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Financial PhraseBank Dataset"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label\n",
       "0  According to Gran , the company has no plans t...      1\n",
       "1  Technopolis plans to develop in stages an area...      1\n",
       "2  The international electronic industry company ...      0\n",
       "3  With the new production plant the company woul...      2\n",
       "4  According to the company 's updated strategy f...      2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### FiQa 2018 Dataset"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>snippets</th>\n",
       "      <th>target</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>aspects</th>\n",
       "      <th>format</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Still short $LNG from $11.70 area...next stop ...</td>\n",
       "      <td>['Still short $LNG from $11.70 area...next sto...</td>\n",
       "      <td>LNG</td>\n",
       "      <td>-0.543</td>\n",
       "      <td>['Stock/Price Action/Volatility/Short Selling']</td>\n",
       "      <td>post</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$PLUG bear raid</td>\n",
       "      <td>['bear raid']</td>\n",
       "      <td>PLUG</td>\n",
       "      <td>-0.480</td>\n",
       "      <td>['Stock/Price Action/Bearish']</td>\n",
       "      <td>post</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How Kraft-Heinz Merger Came Together in Speedy...</td>\n",
       "      <td>['Merger Came Together in Speedy 10 Weeks']</td>\n",
       "      <td>Kraft</td>\n",
       "      <td>0.214</td>\n",
       "      <td>['Corporate/M&amp;A/M&amp;A']</td>\n",
       "      <td>headline</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Slump in Weir leads FTSE down from record high</td>\n",
       "      <td>['down from record high']</td>\n",
       "      <td>Weir</td>\n",
       "      <td>-0.827</td>\n",
       "      <td>['Market/Volatility/Volatility']</td>\n",
       "      <td>headline</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$AAPL bounces off support, it seems</td>\n",
       "      <td>['bounces off support']</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.443</td>\n",
       "      <td>['Stock/Price Action/Bullish/Bullish Behavior']</td>\n",
       "      <td>post</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  Still short $LNG from $11.70 area...next stop ...   \n",
       "1                                    $PLUG bear raid   \n",
       "2  How Kraft-Heinz Merger Came Together in Speedy...   \n",
       "3     Slump in Weir leads FTSE down from record high   \n",
       "4                $AAPL bounces off support, it seems   \n",
       "\n",
       "                                            snippets target  sentiment_score  \\\n",
       "0  ['Still short $LNG from $11.70 area...next sto...    LNG           -0.543   \n",
       "1                                      ['bear raid']   PLUG           -0.480   \n",
       "2        ['Merger Came Together in Speedy 10 Weeks']  Kraft            0.214   \n",
       "3                          ['down from record high']   Weir           -0.827   \n",
       "4                            ['bounces off support']   AAPL            0.443   \n",
       "\n",
       "                                           aspects    format  label  \n",
       "0  ['Stock/Price Action/Volatility/Short Selling']      post      2  \n",
       "1                   ['Stock/Price Action/Bearish']      post      2  \n",
       "2                            ['Corporate/M&A/M&A']  headline      0  \n",
       "3                 ['Market/Volatility/Volatility']  headline      2  \n",
       "4  ['Stock/Price Action/Bullish/Bullish Behavior']      post      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_markdown(\"##### Twitter Dataset\", raw=True)\n",
    "display(twitter.head())\n",
    "\n",
    "display_markdown(\"##### Financial PhraseBank Dataset\", raw=True)\n",
    "display(fpb.head())\n",
    "\n",
    "display_markdown(\"##### FiQa 2018 Dataset\", raw=True)\n",
    "display(fiqa.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceab3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter shape: (11931, 2)\n",
      "FPB shape: (4846, 2)\n",
      "FiQA shape: (1213, 7)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Twitter shape: {twitter.shape}\")\n",
    "print(f\"FPB shape: {fpb.shape}\")\n",
    "print(f\"FiQA shape: {fiqa.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c53f06f",
   "metadata": {},
   "source": [
    "## ðŸ§¹ Basic Cleaning\n",
    "\n",
    "We will:\n",
    "\n",
    "-   Normalize text columns to `sentence`\n",
    "-   Standardize labels across datasets\n",
    "-   Remove duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22572dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text     0\n",
      "label    0\n",
      "dtype: int64 \n",
      "\n",
      "sentence    0\n",
      "label       0\n",
      "dtype: int64 \n",
      "\n",
      "sentence           0\n",
      "snippets           0\n",
      "target             0\n",
      "sentiment_score    0\n",
      "aspects            0\n",
      "format             0\n",
      "label              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "\n",
    "print(twitter.isna().sum(), \"\\n\")\n",
    "print(fpb.isna().sum(), \"\\n\")\n",
    "print(fiqa.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9851c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column normalization complete\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Twitter example"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$BYND - JPMorgan reels in expectations on Beyond Meat https://t.co/bd0xbFGjkT</td>\n",
       "      <td>negative</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        sentence     label   source\n",
       "0  $BYND - JPMorgan reels in expectations on Beyond Meat https://t.co/bd0xbFGjkT  negative  Twitter"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "FPB example"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .</td>\n",
       "      <td>neutral</td>\n",
       "      <td>FPB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                          sentence    label source\n",
       "0  According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .  neutral    FPB"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "FiQA example"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Still short $LNG from $11.70 area...next stop could be down through $9.00. Someone slammed it hard with 230,000 shs this am! More to follow</td>\n",
       "      <td>negative</td>\n",
       "      <td>FiQA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                      sentence     label source\n",
       "0  Still short $LNG from $11.70 area...next stop could be down through $9.00. Someone slammed it hard with 230,000 shs this am! More to follow  negative   FiQA"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Normalize labels\n",
    "twitter.replace({0: \"negative\", 1: \"positive\", 2: \"neutral\"}, inplace=True)\n",
    "fpb.replace({0: \"negative\", 1: \"neutral\", 2: \"positive\"}, inplace=True)\n",
    "fiqa.replace({0: \"positive\", 1: \"neutral\", 2: \"negative\"}, inplace=True)\n",
    "\n",
    "# Rename + tag sources\n",
    "twitter.rename(columns={\"text\": \"sentence\"}, inplace=True)\n",
    "twitter[\"source\"] = \"Twitter\"\n",
    "fpb[\"source\"] = \"FPB\"\n",
    "fiqa[\"source\"] = \"FiQA\"\n",
    "\n",
    "# Drop unused columns from FiQA\n",
    "fiqa.drop(\n",
    "    columns=[\"snippets\", \"target\", \"sentiment_score\", \"aspects\", \"format\"],\n",
    "    errors=\"ignore\",\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "print(\"Column normalization complete\")\n",
    "display_markdown(\"Twitter example\", raw=True)\n",
    "display(twitter.head(1))\n",
    "display_markdown(\"FPB example\", raw=True)\n",
    "display(fpb.head(1))\n",
    "display_markdown(\"FiQA example\", raw=True)\n",
    "display(fiqa.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798fe148",
   "metadata": {},
   "source": [
    "#### Remove Duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a02998f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping duplicates...\n",
      "Twitter duplicates removed: 0\n",
      "FPB duplicates removed: 8\n",
      "FiQA duplicates removed: 102\n"
     ]
    }
   ],
   "source": [
    "print(\"Dropping duplicates...\")\n",
    "\n",
    "before = twitter.shape[0]\n",
    "twitter.drop_duplicates(subset=\"sentence\", inplace=True)\n",
    "print(f\"Twitter duplicates removed: {before - twitter.shape[0]}\")\n",
    "\n",
    "before = fpb.shape[0]\n",
    "fpb.drop_duplicates(subset=\"sentence\", inplace=True)\n",
    "print(f\"FPB duplicates removed: {before - fpb.shape[0]}\")\n",
    "\n",
    "before = fiqa.shape[0]\n",
    "fiqa.drop_duplicates(subset=\"sentence\", inplace=True)\n",
    "print(f\"FiQA duplicates removed: {before - fiqa.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783ccb88",
   "metadata": {},
   "source": [
    "#### Clean Text\n",
    "\n",
    "We apply cleaning to:\n",
    "\n",
    "-   Remove URLs and non-alphanumerics\n",
    "-   Normalize spacing\n",
    "\n",
    "The function is defined below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7bee26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kenya Cuts Rates After Scrapping LoanPrice Cap to Boost Growth\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    if pd.isnull(text):\n",
    "        return \"\"\n",
    "    text = re.sub(r\"http\\S+|www\\.\\S+\", \"\", text)  # remove links\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)  # remove non-alphanumerics\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # normalize spacing\n",
    "    return text\n",
    "\n",
    "\n",
    "print(\"Cleaning text...\")\n",
    "\n",
    "twitter[\"sentence\"] = twitter[\"sentence\"].apply(clean_text)\n",
    "fpb[\"sentence\"] = fpb[\"sentence\"].apply(clean_text)\n",
    "fiqa[\"sentence\"] = fiqa[\"sentence\"].apply(clean_text)\n",
    "\n",
    "print(\"ðŸ”Ž Sample cleaned sentence:\")\n",
    "print(twitter.sample(1)[\"sentence\"].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837b620e",
   "metadata": {},
   "source": [
    "### Combine Datasets & Check Distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7ed937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset shape: (17880, 3)\n",
      "\n",
      "Label distribution:\n",
      "label\n",
      "neutral     59.8%\n",
      "positive    24.8%\n",
      "negative    15.3%\n",
      "Name: proportion, dtype: object\n",
      "\n",
      "Source distribution:\n",
      "source\n",
      "Twitter    11931\n",
      "FPB         4838\n",
      "FiQA        1111\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "all_data = pd.concat([twitter, fpb, fiqa], ignore_index=True)\n",
    "\n",
    "print(f\"Combined dataset shape: {all_data.shape}\")\n",
    "print(\"\\nLabel distribution:\")\n",
    "print((all_data[\"label\"].value_counts(normalize=True) * 100).round(1).astype(str) + \"%\")\n",
    "print(\"\\nSource distribution:\")\n",
    "print(all_data[\"source\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64e523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(data=all_data, x=\"label\", order=[\"positive\", \"neutral\", \"negative\"])\n",
    "plt.title(\"Label Distribution in Combined Dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7a84b3",
   "metadata": {},
   "source": [
    "### Train/Validation Split\n",
    "\n",
    "We stratify by label to preserve class balance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dc9777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 16092\n",
      "Validation size: 1788\n",
      "\n",
      "Train label distribution:\n",
      " label\n",
      "neutral     0.598\n",
      "positive    0.248\n",
      "negative    0.153\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Validation label distribution:\n",
      " label\n",
      "neutral     0.598\n",
      "positive    0.248\n",
      "negative    0.153\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df = train_test_split(\n",
    "    all_data, test_size=0.1, stratify=all_data[\"label\"], random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train size: {len(train_df)}\")\n",
    "print(f\"Validation size: {len(val_df)}\")\n",
    "\n",
    "print(\n",
    "    \"\\nTrain label distribution:\\n\",\n",
    "    train_df[\"label\"].value_counts(normalize=True).round(3),\n",
    ")\n",
    "print(\n",
    "    \"\\nValidation label distribution:\\n\",\n",
    "    val_df[\"label\"].value_counts(normalize=True).round(3),\n",
    ")\n",
    "\n",
    "# Save processed datasets\n",
    "train_df.to_csv(\"../data/processed/train.csv\", index=False)\n",
    "val_df.to_csv(\"../data/processed/val.csv\", index=False)\n",
    "all_data.to_csv(\"../data/processed/data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f74835",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "-   Loaded 3 datasets (Twitter, FPB, FiQA)\n",
    "-   Cleaned and standardized sentence + label columns\n",
    "-   Removed 10K+ duplicates across sources\n",
    "-   Cleaned sentence text for modeling\n",
    "-   Created stratified train/val split\n",
    "-   Saved processed files for downstream model training\n",
    "\n",
    "Next: Open `2_logistic_regression_baseline.ipynb` to benchmark a classical model!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
